{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHN+0n4xPXHkXf0LzjiGZP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. BERT & GPT**"],"metadata":{"id":"GytVMMci__6K"}},{"cell_type":"markdown","source":["### 1. BERT (Bidirectional Encoder Representations from Transformers)\n","BERT는 트랜스포머의 인코더 구조만 사용한 모델로, 문장을 이해하는 데 최적화되어 있습니다. 학습은 문장 속 단어를 가려 맞히는 마스크드 언어모델(MLM)과 두 문장이 이어지는지 판별하는 NSP 방식을 통해 진행되며, 이 과정에서 단어의 앞뒤 문맥을 동시에 참고하는 양방향(Bidirectional) 이해 능력을 갖추게 됩니다. 이러한 특성 덕분에 BERT는 문장 분류, 감정 분석, 질의응답, 문장 유사도 계산 등과 같은 문맥 이해 중심의 자연어 처리 과제에서 강력한 성능을 발휘합니다."],"metadata":{"id":"VLSF28IUAEx6"}},{"cell_type":"markdown","source":["### 2. GPT (Generative Pre-trained Transformer)\n","<a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\">GPT</a>는 트랜스포머의 디코더 구조만 사용하는 모델로, 문장을 생성하는 데 특화되어 있습니다. 학습은 앞 단어들을 보고 다음 단어를 예측하는 오토리그레시브(Autoregressive) 방식으로 진행되며, 이 과정에서 왼쪽에서 오른쪽으로 이어지는 단방향 문맥을 활용합니다. 덕분에 GPT는 문장을 자연스럽게 이어 쓰는 능력이 뛰어나며, 대화, 글쓰기, 요약, 번역 등과 같은 생성 중심의 자연어 처리 과제에서 강한 성능을 발휘합니다.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/cON4Z5/btsQfwabG6l/AAAAAAAAAAAAAAAAAAAAAIbdwg9Mvs_ygPZ2a4wUiEddA9P0Rwh_hAuF9gteT0SV/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=V2A8XzgwQahz%2FHhbZYajnLIe%2Fas%3D\">\n","\n","<img src=\"https://blog.kakaocdn.net/dna/dVC0iN/btsQgq8BEqz/AAAAAAAAAAAAAAAAAAAAABuzj2HwBBX6X5x_rPJpLVYX4txls-HeVi6BAwnXfAdt/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=b29Heha3SYWXRYETbPMPrjDH%2Fyc%3D\">\n","\n","<img src=\"https://blog.kakaocdn.net/dna/b5BIBc/btsQhhXCNp2/AAAAAAAAAAAAAAAAAAAAACbkaUcAlrcO4JLYH2JtUUEz6RIO8H__k_MlW3nRTGZ4/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=fmWzuP1BBeCxPYe%2BjGMRlL%2FZnd8%3D\">"],"metadata":{"id":"1_uorUM4AcWB"}},{"cell_type":"markdown","source":["# **2. 모델 구조 개선**"],"metadata":{"id":"o7pn4nvKBu3q"}},{"cell_type":"markdown","source":["## 1. Transformer-XL (2019)\n","Transformer-XL은 긴 문장을 다루기 위해 세그먼트 간 메모리 재사용과 상대적 위치 인코딩을 도입하여 트랜스포머에 실질적인 ‘순환성’을 부여한 모델입니다. 이를 통해 이전 구간의 정보를 효율적으로 활용하면서 긴 문맥에서도 안정적으로 학습할 수 있었고, 특히 언어모델링에서 장거리 의존성을 효과적으로 처리하며 퍼플렉시티(perplexity)를 크게 개선하는 성과를 거두었습니다."],"metadata":{"id":"QbrvdG2YBxeJ"}},{"cell_type":"markdown","source":["## 2. XLNet (2019)\n","XLNet은 BERT의 MLM과 GPT의 오토리그레시브 방식을 결합한 Permutation Language Modeling을 제안(단어 순서를 랜덤하게 바꾼 여러 경우의 수를 만들어 놓고, 그 순서에 맞게 다음 단어 맞히기 학습을 시키는 아이디어)했습니다. 이를 통해 양방향 문맥을 보존하면서도 [MASK] 토큰 문제를 피할 수 있었고, 당시 여러 벤치마크에서 BERT를 능가하는 성능을 보였습니다."],"metadata":{"id":"perpkVyOB0cB"}},{"cell_type":"markdown","source":["## 3. RoBERTa (2019)\n","<a href=\"https://arxiv.org/pdf/1907.11692\">RoBERTa</a>는 BERT의 구조를 유지하면서 학습 데이터를 늘리고, NSP를 제거하고, 배치 크기와 학습 시간을 확장하는 단순한 최적화로도 성능이 크게 향상됨을 보여주었습니다. 이는 모델 구조보다 학습 전략과 데이터 규모가 중요하다는 교훈을 남겼습니다."],"metadata":{"id":"rYhYT1bpCVa6"}},{"cell_type":"markdown","source":["## 4. ALBERT (2019)\n","<a href=\"https://arxiv.org/pdf/1909.11942\">ALBERT</a>는 “경량화된 BERT”로, 파라미터 공유와 임베딩 분해(embedding factorization)를 통해 모델 크기를 획기적으로 줄이면서도 성능을 유지했습니다. 이 덕분에 큰 모델을 더 효율적으로 학습하고 배포할 수 있었습니다."],"metadata":{"id":"JnGtA3BWDEXB"}},{"cell_type":"markdown","source":["## 5. T5 (2019)\n","T5는 모든 NLP 문제를 텍스트-투-텍스트 문제로 통일한 모델입니다. 번역, 요약, 질의응답, 분류 등 서로 다른 태스크를 “입력을 텍스트, 출력을 텍스트”로 변환해 하나의 모델로 처리할 수 있게 했습니다. 이는 이후 범용 언어모델 연구의 중요한 기반이 되었습니다."],"metadata":{"id":"TBwQWIZGDrvh"}},{"cell_type":"markdown","source":["## 6. Longformer (2020)\n","긴 문서를 처리하기 위해 제안된 Longformer는 Sparse Attention(드문 어텐션 패턴)을 도입하여 어텐션 계산량을 줄이면서 수천 단어 길이의 문서를 처리할 수 있게 했습니다. 긴 문서 요약, 법률 문서 분석 등에서 강점을 보였습니다."],"metadata":{"id":"O7BTi3MCECvR"}},{"cell_type":"markdown","source":["## 7. GPT-3 (2020)\n","<a href=\"https://arxiv.org/abs/2005.14165\">GPT-3</a>는 175B 파라미터를 가진 초대형 언어모델로, Few-shot / Zero-shot Learning이 가능함을 보여주었습니다. 즉, 태스크별 파인튜닝 없이도 간단한 프롬프트만으로 다양한 과제를 수행할 수 있어, 대규모 언어모델(LLM)의 시대를 열었습니다.\n","\n","- **Few-shot Learning**<br>\n","    Few-shot Learning은 새로운 작업이나 클래스를 풀 때 많은 학습 데이터를 쓰지 않고, 단 몇 개의 예시(샘플)만 보고도 규칙을 파악해 문제를 해결하는 방법입니다. 전통적으로는 메타러닝이나 프로토타입 네트워크처럼 임베딩 공간에서 클래스 간 거리를 계산하는 방식이 사용되며, 최근에는 대규모 언어모델에 작업 설명과 예시 몇 개를 프롬프트로 넣어 바로 학습 효과를 얻는 in-context learning이 널리 활용됩니다. 즉, “예시 몇 개만 보여주고 곧바로 따라 하게 만드는 학습 방식”이라 할 수 있습니다.\n","    > 몇장 안주고 러닝하겠다\n","\n","- **Zero-shot Learning**<br>\n","    Zero-shot Learning은 새로운 작업이나 클래스를 만났을 때 예시 데이터(샘플)를 전혀 제공하지 않고, 사전학습된 모델이 이미 가진 일반 지식과 라벨 이름·속성·설명 같은 추가 정보만으로 문제를 해결하는 방법입니다. 예를 들어 “문장의 감정을 긍정/부정으로 분류하라”라는 지시만 주거나, 이미지 분류에서 클래스 이름을 텍스트로 입력해 의미 공간에서 매칭하는 식입니다. 즉, “예시 없이 설명만 보고 곧바로 수행하는 학습 방식”이라 할 수 있으며, 데이터가 전혀 없는 상황에서 빠르게 적용할 수 있다는 장점이 있습니다.\n","- **In-context Learning**<br>\n","    In-context Learning은 사전 학습된 대규모 언어모델에 새로운 작업을 시킬 때, 모델의 파라미터를 추가로 학습시키지 않고 프롬프트 안에 작업 설명과 몇 개의 예시(입력-출력 쌍)를 넣어 주는 방식입니다. 모델은 이 예시들을 문맥(context)으로 삼아 규칙을 추론하고, 이어지는 새로운 입력에 맞춰 답을 생성합니다. 즉, “모델이 대화 맥락 속 예시를 보고 즉석에서 학습한 것처럼 동작하는 능력”으로, Zero-shot(예시 없음)이나 Few-shot(소수 예시) 학습의 기반이 되는 개념입니다.\n","\n","\n","<img src=\"https://blog.kakaocdn.net/dna/t0H8R/btsQelHh0i8/AAAAAAAAAAAAAAAAAAAAAIbiB6x8GU29Mmy7kcK--Zn8ELZy_KcQbljmMoq9wZ7B/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=rTARBQtIwh1mm%2B1usyKB8YQucnI%3D\">"],"metadata":{"id":"9cDIEFVFEb5p"}},{"cell_type":"markdown","source":["## 8. ChatGPT (2022)\n","ChatGPT는 GPT-3.5 계열에 인간 피드백 강화학습(RLHF)을 적용해 대화 품질을 높였습니다. 단순히 언어를 예측하는 수준을 넘어 대화 맥락 이해, 안전성, 응답 품질을 개선하며 실제 활용도를 크게 끌어올렸습니다."],"metadata":{"id":"i22G3Gb7HA1Z"}},{"cell_type":"markdown","source":["## 9. GPT-4 (2023)\n","<a href=\"https://arxiv.org/abs/2303.08774\">GPT-4</a>는 멀티모달 입력(텍스트 + 이미지)을 지원하며, 복잡한 추론, 장문 이해, 다국어 처리 능력을 크게 향상시켰습니다. LLM이 실질적인 지식 활용 플랫폼으로 확장되는 기반을 마련했습니다."],"metadata":{"id":"2mlQiCa7Hd1Y"}},{"cell_type":"markdown","source":["# **3. 학습 테크닉의 발전**"],"metadata":{"id":"F_z0gY8eHo5h"}},{"cell_type":"markdown","source":["## 1. Transfer Learning\n","전이 학습(Transfer Learning)은 한 작업(Task)에서 학습한 지식을 다른 관련 작업에 적용하는 머신러닝 기법입니다. 일반적으로 대량의 데이터와 연산 자원이 필요한 모델을 처음부터 새롭게 훈련하는 대신, 사전 훈련된 모델(Pre-trained Model)의 가중치를 가져와 새로운 데이터에 맞게 일부 층을 조정(Fine-tuning)하거나 특정 기능을 고정(Feature Extraction)하여 활용합니다. 예를 들어, 이미지 분류 모델로 사전 훈련된 CNN(합성곱 신경망) 모델의 초기 계층을 고정하고, 마지막 분류 계층만 새로운 데이터에 맞게 학습시키는 방식이 대표적입니다. 이는 데이터가 적거나 학습 시간이 제한된 상황에서 높은 성능을 얻을 수 있도록 도와주며, 자연어 처리(NLP), 컴퓨터 비전(CV) 등 다양한 분야에서 널리 사용됩니다."],"metadata":{"id":"uGJkWT-fH9ug"}},{"cell_type":"markdown","source":["## 2. Multi-task Learning\n","멀티 태스크 러닝(Multi-task Learning, MTL)은 하나의 모델이 여러 관련된 작업(Task)을 동시에 학습하도록 하는 머신러닝 기법입니다. 이는 여러 개의 작업이 공통된 정보를 공유할 수 있다는 가정하에, 하나의 모델이 다양한 태스크에서 학습한 지식을 활용하여 성능을 향상시키도록 합니다. 일반적으로 MTL 모델은 공유된 표현 학습(Shared Representation Learning)을 통해 서로 다른 태스크 간에 특징(feature)을 공유하며, 이를 통해 데이터 효율성을 높이고 과적합(overfitting)을 방지할 수 있습니다. 예를 들어, 자연어 처리(NLP)에서는 문장 분류, 개체명 인식(NER), 감정 분석 등의 작업을 하나의 모델에서 함께 학습할 수 있으며, 컴퓨터 비전에서는 물체 감지(Object Detection)와 이미지 분할(Segmentation)을 동시에 수행할 수 있습니다. MTL은 모델이 일반화 성능을 높이고 특정 태스크에 대한 편향을 줄이는 데 유용하게 활용됩니다. <a href=\"https://arxiv.org/abs/2012.14631\">[논문]</a>"],"metadata":{"id":"d-w6rIybIU2o"}},{"cell_type":"markdown","source":["## 3. Zero-shot & Few-shot Learning\n","Zero-shot Learning(ZSL)과 Few-shot Learning(FSL)은 적은 양의 데이터 또는 전혀 학습되지 않은 클래스에 대해 모델이 일반화하여 예측할 수 있도록 하는 기법입니다. Zero-shot Learning(ZSL)은 특정 태스크나 클래스에 대한 사전 학습 없이, 모델이 기존에 학습한 개념과 관계를 활용하여 새로운 개념을 이해하고 예측하는 방법입니다. 예를 들어, 이미지 분류에서 \"코끼리\"라는 클래스를 학습한 적이 없더라도, \"큰 몸집, 긴 코\"와 같은 속성 정보를 기반으로 새로운 클래스를 예측할 수 있습니다. 반면, Few-shot Learning(FSL)은 매우 적은 데이터 샘플(예: 1~5개)만 가지고도 새로운 태스크를 학습할 수 있도록 하는 방법으로, 대표적인 접근법으로는 메타 학습(Meta-learning)과 사전 훈련된 대규모 모델을 활용한 방법이 있습니다. 이러한 기법들은 특히 자연어 처리(NLP), 이미지 분류, 의료 진단 등 데이터가 제한적인 환경에서 강력한 성능을 발휘합니다."],"metadata":{"id":"gR9WsOyXL51D"}},{"cell_type":"markdown","source":["## 4. Hierachical Attention\n","Hierarchical Attention(계층적 어텐션)은 자연어 처리(NLP)에서 문서 또는 긴 문장을 보다 효과적으로 이해하기 위해 어텐션 메커니즘을 계층적으로 적용하는 기법입니다. 일반적인 어텐션 메커니즘은 모든 단어에 동일한 방식으로 가중치를 부여하지만, 계층적 어텐션은 문서 구조를 반영하여 단어 수준(word-level) 어텐션과 문장 수준(sentence-level) 어텐션을 각각 학습합니다. 먼저 단어 수준 어텐션을 사용하여 각 문장에서 중요한 단어를 강조한 후, 문장 수준 어텐션을 통해 전체 문서에서 중요한 문장을 추출하는 방식으로 동작합니다. 이를 통해 모델은 긴 문서에서도 핵심 정보를 효과적으로 추출할 수 있으며, 감성 분석, 문서 요약, 기계 번역 등 다양한 NLP 태스크에서 성능을 향상시키는 데 활용됩니다. 대표적인 예로는 Hierarchical Attention Networks(HAN) 모델이 있으며, 이는 문맥을 보다 깊이 있게 반영하여 문서 분류 작업에서 강력한 성능을 보입니다."],"metadata":{"id":"ZdwEnWjLM4RZ"}},{"cell_type":"markdown","source":["## 5. Knowledge Distillation\n","Knowledge Distillation(지식 증류)은 크고 복잡한 모델(Teacher Model)의 지식을 작은 모델(Student Model)에 전달하여 성능을 유지하면서도 경량화하는 모델 압축 기법입니다. 일반적으로 대규모 신경망은 높은 성능을 가지지만 연산 비용이 크고 실시간 응용에 적합하지 않은 경우가 많습니다. 이를 해결하기 위해 Knowledge Distillation에서는 Teacher Model이 예측한 소프트 확률 분포(Soft Targets)를 Student Model이 학습하도록 하여 일반적인 정답 레이블(Hard Labels)보다 더 풍부한 정보(예: 클래스 간 관계)를 제공받을 수 있도록 합니다. 이 과정에서 온도 매개변수(Temperature Scaling)를 활용하여 Soft Targets의 정보를 조절하며, Student Model은 이를 통해 일반화 성능을 개선하고 모델의 크기와 추론 속도를 최적화할 수 있습니다. Knowledge Distillation은 모바일 기기, 임베디드 시스템 등 제한된 자원 환경에서 강력한 모델을 구현하는 데 유용하며, 자연어 처리(NLP), 컴퓨터 비전(CV) 등 다양한 분야에서 널리 활용됩니다.\n","\n","> 선생님과 제자 같은 모델(?)"],"metadata":{"id":"d_rReuhlM7jY"}},{"cell_type":"markdown","source":["## 6. Human Feedback 기반의 Reinforcement Learning\n","Human Feedback 기반 강화 학습(RLHF, Reinforcement Learning from Human Feedback)은 전통적인 강화 학습(RL)에서 보상 함수(Reward Function)를 사람이 직접 제공하는 피드백을 활용하여 학습하는 방법입니다. 일반적인 RL에서는 환경에서 자동으로 계산된 보상을 기반으로 에이전트가 최적의 행동을 학습하지만, RLHF에서는 사람이 직접 행동에 대한 선호도(Preference)나 보상을 제공하여 보다 직관적이고 정교한 학습이 가능합니다. 이 방법은 특히 명확한 보상 설계가 어려운 자연어 처리(NLP)나 윤리적 AI 개발에서 효과적이며, 예를 들어 OpenAI의 GPT 모델은 RLHF를 활용하여 사용자에게 더욱 자연스럽고 유용한 응답을 생성하도록 학습되었습니다. RLHF는 먼저 사람이 데이터에 태그를 달아 보상 모델(Reward Model)을 학습하고, 이후 강화 학습을 통해 모델이 인간의 선호도를 반영하도록 최적화하는 과정을 거칩니다. 이를 통해 AI 모델이 단순히 성능 최적화뿐만 아니라, 보다 인간 친화적이고 윤리적인 결과를 생성할 수 있도록 돕습니다."],"metadata":{"id":"_PJmuDGTNbkI"}},{"cell_type":"markdown","source":["## 7. PEFT\n","PEFT(Parameter-Efficient Fine-Tuning)는 거대한 사전학습 모델을 새로운 태스크에 맞게 미세조정할 때, 전체 가중치를 학습하지 않고 극히 일부의 파라미터만 조정하는 기법들의 총칭입니다. 대표적으로 LoRA, 어댑터, 프롬프트 튜닝 같은 방법이 있으며, 이들은 본체 모델을 고정한 채 작은 모듈이나 추가 파라미터만 학습하여 메모리와 연산 비용을 크게 줄입니다. 이를 통해 수십억~수천억 파라미터 모델도 일반 GPU 환경에서 효율적으로 파인튜닝할 수 있고, 태스크별로 필요한 추가 저장 용량도 최소화할 수 있어 최근 대규모 언어모델 활용에서 사실상 표준 접근 방식으로 자리 잡았습니다."],"metadata":{"id":"glfWaw2-NeRa"}},{"cell_type":"code","source":[],"metadata":{"id":"LsB6FkT4Ev_T"},"execution_count":null,"outputs":[]}]}