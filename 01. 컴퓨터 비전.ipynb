{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMad39KUJwZ6YQr33W1iitB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. 컴퓨터 비전**\n","컴퓨터 비전은 인공지능(AI)의 한 분야로, 컴퓨터가 인간처럼 이미지나 영상을 이해하고 분석할 수 있도록 하는 기술입니다. 이는 객체 검출, 이미지 분류, 얼굴 인식, 장면 이해 등 다양한 작업을 포함하며, 주로 머신러닝과 딥러닝을 활용하여 이미지 속 특징을 추출하고 패턴을 학습합니다. 예를 들어, 자율주행 자동차는 컴퓨터 비전을 사용하여 도로의 차선, 보행자, 신호등을 인식하며, 의료 영상 분석에서는 CT나 MRI 이미지를 분석하여 질병을 진단할 수 있습니다. 최근에는 합성곱 신경망(CNN)과 같은 딥러닝 모델이 발전하면서 컴퓨터 비전의 성능이 크게 향상되었으며, 다양한 산업에서 활발히 활용되고 있습니다."],"metadata":{"id":"T3ff1LLW30cd"}},{"cell_type":"markdown","source":["### 컴퓨터 비전에서의 프레임워크\n","컴퓨터 비전에서 주로 사용하는 프레임워크로는 OpenCV, TensorFlow, PyTorch 등이 있습니다. OpenCV는 이미지 처리 및 컴퓨터 비전 작업을 위한 오픈소스 라이브러리로, 빠른 속도와 다양한 기능을 제공하여 전처리 및 간단한 비전 작업에 많이 활용됩니다. TensorFlow와 PyTorch는 딥러닝 기반의 컴퓨터 비전 모델을 학습시키는 데 사용되는 대표적인 프레임워크로, 합성곱 신경망(CNN), 객체 검출, 이미지 분할 등의 작업을 쉽게 구현할 수 있도록 지원합니다. TensorFlow는 Google에서 개발한 프레임워크로 대규모 배포와 성능 최적화에 강점을 가지며, PyTorch는 직관적인 코드 작성과 디버깅이 용이하여 연구 및 실험에서 많이 사용됩니다.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/baYZR7/btsMgRiA3C5/AAAAAAAAAAAAAAAAAAAAAGoh4VDF_Xrxs7SxBKQjukarCldf66qmJyT6IOXiUqGY/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=qyfY2H5ggM278gxkFv4EMZD1nUQ%3D\" width=600>"],"metadata":{"id":"HgHIbwWI4U-N"}},{"cell_type":"markdown","source":["# **2. 컴퓨터 비전에서의 데이터셋**\n","컴퓨터 비전에서 데이터셋은 모델의 성능을 결정하는 가장 중요한 요소 중 하나입니다. 딥러닝 모델은 대량의 이미지 데이터를 학습하여 패턴을 인식하고 일반화하는 능력을 갖추기 때문에, 양질의 데이터셋이 필수적입니다. 데이터셋이 다양하고 균형 잡혀 있을수록 모델은 과적합을 피하고 실제 환경에서도 잘 작동할 가능성이 높아집니다. 예를 들어, ImageNet, COCO, Pascal VOC 같은 대규모 데이터셋은 객체 분류 및 검출 모델 학습에 널리 사용되며, MNIST, CIFAR-10, Fashion-MNIST 등은 기초적인 이미지 분류 실험에 활용됩니다. 또한, 특정 도메인에 특화된 의료 영상 데이터셋이나 자율주행용 데이터셋도 존재하며, 실제 애플리케이션에서 중요한 역할을 합니다. 좋은 데이터셋을 구축하기 위해서는 이미지의 품질, 다양한 환경에서의 데이터 확보, 라벨링의 정확성 등이 중요하며, 최근에는 데이터 증강(Augmentation)과 생성 모델(GANs)을 활용하여 부족한 데이터를 보완하는 기법도 활용되고 있습니다."],"metadata":{"id":"8j4Qz6-I4PQs"}},{"cell_type":"markdown","source":["### 2-1. Papers with Code\n","\n","<a href=\"https://paperswithcode.com/\">Papers with Code</a>는 최신 머신러닝 및 인공지능 연구 논문과 함께 해당 논문의 코드 구현을 제공하는 오픈 플랫폼입니다. 이 사이트는 연구자와 개발자가 논문을 쉽게 탐색하고, 논문의 내용을 직접 실험해 볼 수 있도록 돕습니다. 특히, 컴퓨터 비전, 자연어 처리(NLP), 강화 학습 등 다양한 분야에서 최신 **SOTA(State-of-the-Art) 모델과 성능 비교 표를 제공하여 연구 동향을 빠르게 파악할 수 있습니다. 또한, 각 논문과 관련된 데이터셋, 평가 지표, 코드 저장소(GitHub 링크) 등을 함께 제공하여 연구자들이 최신 연구를 직접 테스트하고 개선할 수 있도록 지원합니다. 이를 통해 학계와 산업 간의 지식 공유가 활발하게 이루어지며, 최신 AI 기술을 실무에 적용하는 데 유용한 자료로 활용되고 있습니다.\n","\n","**SOTA(State-of-the-Art) : 순위권에 들어오는 최신 모델 랭킹<br>\n","특정 분야에서 현재까지 발표된 모델 중 가장 우수한 성능을 보이는 모델을 의미합니다. Papers with Code에서는 이러한 SOTA 모델들의 순위와 관련 논문, 코드를 제공하여 최신 연구 동향을 파악하는 데 도움을 줍니다."],"metadata":{"id":"uHv66b1N5ZK3"}},{"cell_type":"markdown","source":["### 2-2. AI Hub\n","\n","<a href=\"https://www.aihub.or.kr/\">AI Hub</a>는 한국의 인공지능 데이터 및 알고리즘 공유 플랫폼으로, AI 연구 개발을 지원하기 위해 다양한 데이터셋, 학습용 API, 개발 도구 등을 제공합니다. 한국지능정보사회진흥원(NIA)이 운영하며, 자연어 처리, 컴퓨터 비전, 음성 인식, 자율주행 등 다양한 AI 분야에서 활용할 수 있는 국내 특화 데이터셋을 제공하는 것이 특징입니다. 연구자 및 개발자는 AI Hub에서 공개된 데이터를 활용하여 AI 모델을 학습시키거나 성능을 평가할 수 있으며, 일부 데이터는 직접 다운로드하여 사용할 수도 있습니다. 또한, AI 알고리즘 개발 지원, AI 윤리 가이드라인, AI 관련 교육 자료 등도 제공하여 AI 생태계 활성화에 기여하고 있습니다. 특히, 한국어 기반의 데이터가 많아 한국어 AI 모델 개발에 매우 유용한 플랫폼입니다."],"metadata":{"id":"uw2HtP-96k2N"}},{"cell_type":"markdown","source":["### 2-3.COCO\n","\n","<a href=\"https://cocodataset.org/#home\">COCO(Common Objects in Context)</a> 데이터셋은 컴퓨터 비전 분야에서 객체 검출(Object Detection), 이미지 분할(Image Segmentation), 이미지 캡셔닝(Image Captioning) 등의 연구를 위해 널리 사용되는 대규모 데이터셋입니다. Microsoft에서 개발한 이 데이터셋은 일상적인 장면에서 촬영된 다양한 객체가 포함된 이미지들로 구성되어 있으며, 약 33만 개의 이미지와 150만 개 이상의 객체 **주석(Annotation)이 포함되어 있습니다. COCO 데이터셋의 특징은 정밀한 객체 경계 정보(폴리곤 기반 Segmentation), 다중 객체 포함 이미지, 풍부한 주석 정보(객체 클래스, 키포인트, 캡션 등)입니다. 이러한 특성 덕분에 COCO는 딥러닝 기반의 객체 검출, 세그멘테이션, 인스턴스 검출, 행동 인식 등의 연구에 필수적인 데이터셋으로 자리 잡았으며, 매년 COCO 챌린지를 통해 최신 AI 모델들의 성능을 평가하는 데 사용되고 있습니다.\n","\n","** 주석(Annotation) : 이미지나 영상 데이터에 추가 정보를 표시하는 작업"],"metadata":{"id":"onnRvrrH7Xjv"}},{"cell_type":"markdown","source":["### 2-4. Open Images Dataset\n","\n","<a href=\"https://storage.googleapis.com/openimages/web/download_v7.html\">Open Images Dataset</a>은 Google이 제공하는 대규모 컴퓨터 비전 데이터셋으로, 객체 검출(Object Detection), 이미지 분류(Image Classification), 이미지 세그멘테이션(Image Segmentation) 등의 연구를 위해 설계되었습니다. Open Images 데이터셋은 900만 개 이상의 이미지와 6억 개 이상의 바운딩 박스 주석(Bounding Box Annotation)을 포함하며, 약 600개의 객체 클래스(Label)를 제공합니다. COCO나 Pascal VOC보다 훨씬 많은 객체 수와 방대한 데이터 양을 제공하여 딥러닝 모델의 학습 및 일반화 성능을 높이는 데 유용합니다. 또한, 이미지에는 객체 검출을 위한 바운딩 박스뿐만 아니라 관계 주석(Visual Relationship), 행동 태그(Action Tagging), 랜드마크 정보 등이 포함되어 있어, 다양한 컴퓨터 비전 연구에 활용할 수 있습니다. Open Images는 실제 웹에서 수집된 이미지들로 구성되어 있으며, 보다 현실적인 데이터로 AI 모델을 학습시키는 데 유리한 데이터셋입니다."],"metadata":{"id":"0sQNanya7qxP"}},{"cell_type":"markdown","source":["### 2-5. CheXpert\n","\n","<a href=\"https://stanfordmlgroup.github.io/competitions/chexpert/\">CheXpert 데이터셋</a>은 <mark>의료 영상 분석, 특히 흉부 X-ray 이미지 기반의 질병 진단을 위한 대규모 데이터셋</mark>입니다. Stanford University에서 개발한 이 데이터셋은 총 224,316개의 흉부 X-ray 이미지와 관련된 **14가지 흉부 질환 라벨(예: 폐렴, 기흉, 심장비대 등)**을 포함하고 있습니다. CheXpert는 방사선 전문의의 라벨링을 기반으로 한 신뢰도 높은 주석 데이터를 제공하며, 자동 라벨링 기법을 활용하여 불확실성(Uncertainty)이 포함된 데이터를 처리하는 것이 특징입니다. 이 데이터셋은 딥러닝 기반의 의료 영상 분석 모델을 훈련하고 평가하는 데 중요한 역할을 하며, 의료 AI 분야에서 널리 사용됩니다. 특히, AI를 활용한 자동 진단 시스템 개발, 의료 영상 판독 보조 시스템 연구 등에 활용되며, 연구자들에게 의료 영상 분석의 SOTA(State-of-the-Art) 모델을 평가할 수 있는 벤치마크로 사용됩니다."],"metadata":{"id":"08VqqnOC-QSa"}},{"cell_type":"markdown","source":["### 2-6. KITTI\n","\n","<a href=\"https://www.cvlibs.net/datasets/kitti/\">KITTI 데이터셋</a>은 자율주행 및 컴퓨터 비전 연구를 위한 대표적인 대규모 데이터셋으로, 독일 **카를스루에 공과대학교(KIT)와 토요타 기술연구소(Toyota Technological Institute)**에서 개발하였습니다. 이 데이터셋은 실제 도로 환경에서 촬영된 고해상도 영상과 다양한 센서 데이터를 포함하며, 특히 LiDAR(라이다) 포인트 클라우드, 스테레오 영상, GPS/IMU 데이터를 함께 제공하는 것이 특징입니다. KITTI는 객체 검출(Object Detection), 주행 경로 예측, 깊이 추정(Depth Estimation), SLAM(동시적 위치 추정 및 지도 작성) 등 다양한 연구에 활용되며, 자율주행 AI 및 로보틱스 연구에서 필수적인 벤치마크 데이터셋으로 자리 잡고 있습니다. 또한, 다양한 주행 시나리오(도심, 교외, 고속도로 등)를 포함하여 실제 환경에서의 AI 모델 성능을 평가하는 데 매우 유용합니다."],"metadata":{"id":"aUgRyBVp_Erp"}},{"cell_type":"markdown","source":["# 3. 어노테이션\n","어노테이션(Annotation)은 머신러닝, 특히 지도학습(Supervised Learning)에서 데이터에 대한 정답(라벨)을 부여하는 과정을 의미합니다. 컴퓨터 비전에서는 이미지나 영상 내 객체의 위치, 크기, 카테고리 등을 사람이 직접 지정하거나 자동화된 도구를 이용해 태그하는 작업을 포함합니다. 대표적인 어노테이션 유형으로는 바운딩 박스(Bounding Box) 어노테이션(객체의 위치를 사각형으로 표시), 폴리곤 어노테이션(정확한 윤곽선 표시), 세그멘테이션(Segmentation)(픽셀 단위의 라벨링), 키포인트(Keypoint) 어노테이션(얼굴, 손, 관절 등의 특징점 표시) 등이 있습니다. 이러한 어노테이션 데이터는 딥러닝 모델이 객체를 학습하고 인식하는 데 필수적이며, 데이터 품질이 모델 성능에 직접적인 영향을 미칩니다. 최근에는 자동 어노테이션 도구나 크라우드소싱 플랫폼을 활용하여 대량의 데이터를 효율적으로 라벨링하는 기술도 발전하고 있습니다. [참고](https://dev-sites.tistory.com/90)"],"metadata":{"id":"HkFMnZ2U_u1t"}},{"cell_type":"markdown","source":["### 3-1. 바운딩 박스(Bounding Box)\n","- 객체를 감싸는 사각형 형태의 어노테이션으로, 객체 검출(Object Detection)에서 가장 널리 사용됨.\n","- 예: COCO, PASCAL VOC 데이터셋.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/lqHBV/btsMgH1FePW/AAAAAAAAAAAAAAAAAAAAADCuttaTfWSkSWMvPB1jc8tGuu6wAF8YFujTnprXWJN0/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=tIZ4xZoYX6B1B%2FcIzjOWYbDDHZ8%3D\" width=500>"],"metadata":{"id":"I_ftdPGwAmKI"}},{"cell_type":"markdown","source":["### 3-2. 폴리곤(Polygon) 어노테이션\n","- 불규칙한 형태의 객체를 더 정확하게 표현하기 위해 다각형 형태로 라벨링하는 방식.\n","- 예: 자율주행 차량의 도로 표지판, 건물 경계선 표시.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/LOp2m/btsMg4a5xKb/AAAAAAAAAAAAAAAAAAAAAMaQydCWTPaakkAIj0PdvPSBueNLRGEDhj38NGSwYhpS/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=CYEixZ8upmBwfLUgAyqkZByinc4%3D\" width=500>"],"metadata":{"id":"sFmjT5YWBP7j"}},{"cell_type":"markdown","source":["### 3-3. 세그멘테이션(Segmentation)\n","- 픽셀 단위로 객체를 구분하는 방법으로, 인스턴스 세그멘테이션(Instance Segmentation)과 의미론적 세그멘테이션(Semantic Segmentation)으로 나뉨.\n","- 예: COCO, ADE20K 데이터셋.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/cvcSu8/btsMgIe89SL/AAAAAAAAAAAAAAAAAAAAADyWUXNw80cbpdZ_Ez3Y-pqT9Z1e466io8hcXUpQWPO_/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=Ya7nkXaht08SzCT8Qb259wZgQck%3D\" width=500>\n","\n","- 인스턴스 세그멘테이션 (Instance Segmentation): 의미론적 세그멘테이션처럼 각 픽셀을 클래스로 분류하지만, 동일한 클래스에 속하더라도 개별 객체(인스턴스)를 각각 구분하여 마스크를 생성합니다. 예를 들어, 이미지에 여러 대의 자동차가 있다면 각 자동차를 별개의 객체로 인식하고 분리합니다.\n","- 의미론적 세그멘테이션 (Semantic Segmentation): 이미지의 각 픽셀을 미리 정의된 클래스(예: 사람, 자동차, 도로) 중 하나로 분류합니다. 같은 클래스에 속하는 여러 객체를 개별적으로 구분하지 않고 하나의 덩어리로 인식합니다."],"metadata":{"id":"ovaE1lXfB4p_"}},{"cell_type":"markdown","source":["### 3-4. 키포인트(Keypoint) 어노테이션\n","- 얼굴 인식, 동작 분석 등에 사용되며, 눈, 코, 손목, 팔꿈치 등 특정 지점에 점을 찍어 라벨링.\n","- 예: OpenPose, COCO Keypoints 데이터셋.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/cR8CNJ/btsMiIEv88T/AAAAAAAAAAAAAAAAAAAAALZcJeNLS_nhLdritbZcnEbxW2Ai5dBq9FNsfZIq2ZNy/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=TzOxLijhEWBBgwzCBcNI1Zpv3KQ%3D\">"],"metadata":{"id":"gPQZepBGFp5E"}},{"cell_type":"markdown","source":["### 3-5. 스켈레톤(Skeleton) 어노테이션\n","- 여러 개의 키포인트를 선으로 연결하여 인체의 구조나 포즈를 표현하는 방식.\n","- 예: 행동 인식, 스포츠 분석.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/cxaviI/btsMhRoH08E/AAAAAAAAAAAAAAAAAAAAABcjxCdKNoLrnzrP-kzzeKCHnBo_83I6i35mrC5qLymM/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=AeQpM%2Bwkh4GdNgSNeUiZD99cel0%3D\" width=500>"],"metadata":{"id":"Kj6qoih5F--x"}},{"cell_type":"markdown","source":["### 3-6. 라인(Line) 및 폴리라인(Polyline) 어노테이션\n","- 도로 차선, 경계선 등을 라인 형태로 라벨링하는 방식.\n","- 예: 자율주행에서 도로 차선 감지.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/ZUXVA/btsMhcz6fHs/AAAAAAAAAAAAAAAAAAAAAD9i-VXhb9j0RaXdFlT0d-Y2Pc1cK7XH4BxEHWJBaz0S/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=TVnQePqEH1jHiw4BnG%2FXR6N6Bg0%3D\" width=500>"],"metadata":{"id":"IXodD5zDGSVV"}},{"cell_type":"markdown","source":["### 3-7. 3D 바운딩 박스(3D Bounding Box)\n","- 객체의 길이, 너비, 높이 정보를 포함하여 3차원 공간에서 라벨링하는 방법.\n","- 예: LiDAR 데이터(자율주행).\n","\n","<img src=\"https://blog.kakaocdn.net/dna/bgve2E/btsMiBFty78/AAAAAAAAAAAAAAAAAAAAAAoAYWn1iGoBhVh57G-IGpoFSs6xs-qeSNFPAefeU4EQ/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=DPw%2BgSCFMP0k7hv4MLuCdG4ahkQ%3D\" width=500>"],"metadata":{"id":"4_53Z3tuGgn0"}},{"cell_type":"markdown","source":["### 3-8. 이미지 캡셔닝(Image Captioning) 어노테이션\n","- 이미지의 내용을 설명하는 텍스트 라벨을 추가하는 방식.\n","- 예: COCO Caption 데이터셋.\n","\n","<img src=\"https://blog.kakaocdn.net/dna/pY5Ma/btsMhOr3wp3/AAAAAAAAAAAAAAAAAAAAAHWf4lJw8kaf3HghejCf0l--__FUIrJSCTn6U2V6UZDT/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=mCxNlT0SOkbKnleAxo%2FMl13hpag%3D\" width=300>"],"metadata":{"id":"CZgyPkBOHyab"}},{"cell_type":"markdown","source":["# **4. 어노테이션 도구**\n","\n","어노테이션 도구(Annotation Tool)는 컴퓨터 비전 모델 학습을 위해 이미지나 영상 데이터에 라벨을 부여하는 소프트웨어입니다. 이러한 도구는 바운딩 박스, 폴리곤, 세그멘테이션, 키포인트 등의 다양한 어노테이션 방식을 지원하며, 수작업 또는 자동화된 방법으로 데이터를 라벨링할 수 있도록 도와줍니다. <a href=\"https://dev-sites.tistory.com/90\">참고</a>"],"metadata":{"id":"o_gXAbOLIsT7"}},{"cell_type":"markdown","source":["### CVAT.ai\n","- 어노테이션 도구 <a href=\"https://www.cvat.ai\">[링크]</a>"],"metadata":{"id":"knvRiDF6Jj7I"}},{"cell_type":"markdown","source":["# **5. COCO 데이터셋 어노테이션의 예**"],"metadata":{"id":"q5PElGaDnIGf"}},{"cell_type":"markdown","source":["### JSON 파일 구조\n","\n","```\n","{\n","    \"images\":[...],\n","    \"annotations\":[...],\n","    \"categories\":[...]\n","}\n","\n","images: 이미지에 대한 메타데이터\n","    - id: 이미지 고유 ID\n","    - file_name: 실제 파일 이름\n","    - width, height: 이미지 크기\n","annotations: 객체에 대한 정보\n","    - id: 이미지 고유 ID\n","    - image_id: 객체가 속한 이미지의 ID\n","    - category_id: 클래스 ID\n","    - bbox: [x, y, w, h] 형식의 박스\n","    - area: 객체의 면적\n","    - iscrowd: 1이면 객체가 군집(분리 어려움), 0이면 일반\n","    - segmentation: 폴리곤 형태로 객체의 픽셀 위치를 표시\n","categories: 클래스 정보\n","    - id: 클래스 고유 ID\n","    - name: 클래스 이름\n","    - supercategory: 상위 카테고리\n","```"],"metadata":{"id":"fDCta7rwnQwi"}},{"cell_type":"markdown","source":["# **6. 컴퓨터 비전 대표 Task**"],"metadata":{"id":"Vvj2IRF-toTs"}},{"cell_type":"markdown","source":["### 6-1. 이미지 분류(Image Classification)\n","- 이미지를 하나 입력하면 무엇인지 하나의 라벨로 분류\n","- 손글씨 인식, 질병 진단, 상품 이미지 검색"],"metadata":{"id":"-zfKKMNutshn"}},{"cell_type":"markdown","source":["### 6-2. 객체 탐지(Object Detection)\n","- 이미지에서 여려 개의 객체가 어디에 있는지, 어떤 객체인지 알려줌\n","- 자율주행, CCTV 감시"],"metadata":{"id":"x6cIKogRt-b4"}},{"cell_type":"markdown","source":["### 6-3. 세분화(Segmentation)\n","- 이미지의 모든 픽셀이 어떤 객체에 속하는지 예측\n","    - Semantic Segmentation: 같은 클래스는 모두 같은 색\n","    - Instance Segmentation: 사람 여려명을 각각 다르게 구분\n","- 의료 영상 분석, 배경 제거, 로봇 시각 프로그래밍"],"metadata":{"id":"p4zGz2f1uRlo"}},{"cell_type":"markdown","source":["<img src=\"https://blog.kakaocdn.net/dna/CH81P/btsPXIC0xct/AAAAAAAAAAAAAAAAAAAAAMwa9pAeRsSdR9CmAZuYpJGeCZOJs2pCFiG0tbh_VM3i/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=ZNQYv17Z2DFFyLZNW57vFjRb%2B0c%3D\">"],"metadata":{"id":"XvSGQvG1Zw6n"}},{"cell_type":"code","source":[],"metadata":{"id":"pAPrBeAKZyTe"},"execution_count":null,"outputs":[]}]}